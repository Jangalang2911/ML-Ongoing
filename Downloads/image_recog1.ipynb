{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJtuO77aR42u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "097e1b25-7950-41cb-9ba3-2323a9d38f35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Facial-Expression-Dataset' already exists and is not an empty directory.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/albumentations-team/albumentations\n",
            "  Cloning https://github.com/albumentations-team/albumentations to /tmp/pip-req-build-dpzbf2ab\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/albumentations-team/albumentations /tmp/pip-req-build-dpzbf2ab\n",
            "  Resolved https://github.com/albumentations-team/albumentations to commit 9b0525f479509195a7a7b7c19311d8e63bbc6494\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (1.22.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (0.19.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (6.0)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (0.0.4)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.9/dist-packages (from albumentations==1.3.0) (4.6.0.66)\n",
            "Requirement already satisfied: opencv-python-headless>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.7.0.72)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (1.2.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations==1.3.0) (4.5.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (8.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2.9.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (3.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (2023.3.15)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0) (23.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations==1.3.0) (1.1.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.9/dist-packages (0.6.12)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.14.1+cu116)\n",
            "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (1.13.1+cu116)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (6.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm) (0.13.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (4.65.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (8.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (1.22.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->huggingface-hub->timm) (1.26.15)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.9/dist-packages (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.19.3 in /usr/local/lib/python3.9/dist-packages (from opencv-contrib-python) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/parth1620/Facial-Expression-Dataset.git\n",
        "!pip install -U git+https://github.com/albumentations-team/albumentations\n",
        "!pip install timm\n",
        "!pip install --upgrade opencv-contrib-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import random\n",
        "import os\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms as T"
      ],
      "metadata": {
        "id": "YX_kdrj7SVVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_IMG_FOLDER_PATH = '/content/Facial-Expression-Dataset/train'\n",
        "VALID_IMG_FOLDER_PATH = '/content/Facial-Expression-Dataset/validation'\n",
        "#Augmentations \n",
        "train_augs = T.Compose([\n",
        "    T.RandomHorizontalFlip(),\n",
        "    T.RandomRotation(degrees = (-20, 20)),\n",
        "    T.ToTensor()       #changes dimension from (height, width, channel) to (channel, width, height)\n",
        "])                                         #to prevent overfitting\n",
        "\n",
        "valid_augs = T.Compose([T.ToTensor()])"
      ],
      "metadata": {
        "id": "6Zf5gn_TSb_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainset = ImageFolder(TRAIN_IMG_FOLDER_PATH, train_augs)\n",
        "validset = ImageFolder(VALID_IMG_FOLDER_PATH, valid_augs)"
      ],
      "metadata": {
        "id": "NlVJrZvlUQg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_random_image(trainset):\n",
        "  random.seed(60)\n",
        "  rand_idx = random.random()\n",
        "  rand_idx = rand_idx * len(trainset)\n",
        "\n",
        "  image, label = trainset[int(rand_idx)]\n",
        "  plt.imshow(image.permute(1, 2, 0)) # changing tensor format back for printing\n",
        "\n",
        "  for idx, emotion in enumerate(trainset.class_to_idx.keys()):\n",
        "    if idx == label:\n",
        "      label = emotion\n",
        "    plt.title(label)\n",
        "  plt.show()\n",
        "\n",
        "print_random_image(trainset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "Qo56uWScS5Py",
        "outputId": "06877de5-3627-4b6e-8195-74c42419563b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pickle import TRUE\n",
        "# loading data\n",
        "DEVICE = 'cuda'\n",
        "MODEL_NAME = 'efficientnet_b0'\n",
        "\n",
        "LR = 0.001\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "trainloader = DataLoader(dataset = trainset, batch_size = BATCH_SIZE, shuffle = TRUE)\n",
        "validloader = DataLoader(dataset = validset, batch_size = BATCH_SIZE)\n",
        "\n",
        "for images, labels in trainloader: #fetching just one batch of images and labels; trainloader not subscriptable\n",
        "  break"
      ],
      "metadata": {
        "id": "q3zYFbqlWpZC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "from torch import nn\n",
        "#the shizz\n",
        "\n",
        "class FaceModel(nn.Module):\n",
        "  def __init__(self) -> None:\n",
        "    super(FaceModel, self).__init__()\n",
        "\n",
        "    self.eff_net = timm.create_model(MODEL_NAME, pretrained = True, num_classes = 7)  # the model\n",
        "\n",
        "  def forward(self, image, labels = None):\n",
        "    logits = self.eff_net(image)\n",
        "\n",
        "    if labels is not None:\n",
        "      loss = nn.CrossEntropyLoss()(logits, labels)\n",
        "      return logits, loss\n",
        "\n",
        "    return logits"
      ],
      "metadata": {
        "id": "z6DnC1UOX-An"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model usage\n",
        "model = FaceModel()\n",
        "model.to(DEVICE)"
      ],
      "metadata": {
        "id": "axa5yhy_dKhz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def multiclass_accuracy(y_pred, y_true):\n",
        "  top_p, top_class = y_pred.topk(1, dim = 1)\n",
        "  equals = top_class == y_true.view(*top_class.shape)\n",
        "  return torch.mean(equals.type(torch.FloatTensor))\n",
        "\n",
        "def training_fn(model, dataloader, optimizer, curr_epo):\n",
        "  model.train()\n",
        "  total_loss = 0.0\n",
        "  total_acc = 0.0\n",
        "  token = tqdm(dataloader, desc = \"EPOCH\" + \"[TRAIN]\" + str(curr_epo + 1) + \"/\" + str(EPOCHS))\n",
        "  \n",
        "  for t, data in enumerate(token):\n",
        "    images, labels = data\n",
        "    images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    logits, loss = model(images, labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_acc += multiclass_accuracy(logits, labels)\n",
        "    token.set_postfix({'loss' : '%f' %float(total_loss/(t+1)), 'acc' : '%f' %float(total_acc/(t+1))})\n",
        "\n",
        "  return total_loss/len(dataloader), total_acc/len(dataloader)\n",
        "\n",
        "  "
      ],
      "metadata": {
        "id": "pcc1W3fIdhey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_fn(model, dataloader, curr_epo):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    total_acc = 0.0\n",
        "    token = tqdm(dataloader, desc = \"EPOCH\" + \"[TRAIN]\" + str(curr_epo + 1) + \"/\" + str(EPOCHS))\n",
        "  \n",
        "    for t, data in enumerate(token):\n",
        "       images, labels = data\n",
        "       images, labels = images.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "       logits, loss = model(images, labels)\n",
        "\n",
        "       total_loss += loss.item()\n",
        "       total_acc += multiclass_accuracy(logits, labels)\n",
        "       token.set_postfix({'loss' : '%f' %float(total_loss/(t+1)), 'acc' : '%f' %float(total_acc/(t+1))})\n",
        "\n",
        "    return total_loss/len(dataloader), total_acc/len(dataloader)"
      ],
      "metadata": {
        "id": "oLOu60HpsJ7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training loop\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LR)\n",
        "\n",
        "best_valid_loss = np.Inf\n",
        "\n",
        "for i in range(EPOCHS):\n",
        "  training_loss, training_acc = training_fn(model, trainloader, optimizer, i)\n",
        "  valid_loss, valid_acc = eval_fn(model, validloader, i)\n",
        "  \n",
        "  if valid_loss < best_valid_loss:\n",
        "    torch.save(model.state_dict(), 'best_weights.pt') #saving the parameters of the best iteration yet\n",
        "    print(\"Saved best weights\")\n",
        "    best_valid_loss = valid_loss \n",
        "\n"
      ],
      "metadata": {
        "id": "AFUncAK7p1i-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}